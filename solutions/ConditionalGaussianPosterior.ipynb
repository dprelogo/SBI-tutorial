{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK\n",
    "Follow directly the example from the CMAFLikelihood.\n",
    "However use ConditionalGaussian for the distribution choice.\n",
    "\n",
    "Instead of fitting the likelihood and recovering the posterior (NLE), fit the posterior directly, with prior imposed from the data (NPE).\n",
    "\n",
    "Compare the samples of the posterior with the analytical posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import logging\n",
    "import corner\n",
    "import ultranest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from py21cmlikelihoods import ConditionalGaussian\n",
    "from py21cmlikelihoods.utils import prepare_dataset\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "ultranest_logger = logging.getLogger(\"ultranest\")\n",
    "ultranest_logger.addHandler(logging.NullHandler())\n",
    "ultranest_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# constructing the posterior\n",
    "NDE = ConditionalGaussian(\n",
    "    n_parameters = 5, \n",
    "    n_data = 2, \n",
    "    diagonal_covariance = False,\n",
    "    n_hidden = [50] * 10,\n",
    "    optimizer = tf.optimizers.Adam(1e-4), \n",
    "    kernel_initializer = \"glorot_uniform\",\n",
    "    kernel_initializer_kwargs = {},\n",
    "    # kernel_initializer = tf.keras.initializers.RandomNormal,\n",
    "    # kernel_initializer_kwargs = {\"mean\":0.0, \"stddev\": 1e-3, \"seed\":None},\n",
    "    bias_initializer = \"zeros\",\n",
    "    bias_initializer_kwargs = {},\n",
    "    last_layer_bias_initializer = None,\n",
    "    kernel_regularizer = tf.keras.regularizers.L1L2(l1=0.0, l2=1e-1),\n",
    "    bias_regularizer = tf.keras.regularizers.L1L2(l1=0.0, l2=1e-3),\n",
    "    regularize_last_layer = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# constructing the training set\n",
    "mu_0 = np.random.normal(0.0, 1.0, size = 100000)\n",
    "sigma_0 = np.random.uniform(0.5, 5.0, size = 100000)\n",
    "params = np.stack([mu_0, sigma_0], axis = -1)\n",
    "data = np.array([np.random.multivariate_normal(np.arange(1, 6)**2 * m, np.diag(np.arange(1, 6)**2 * s**2)) for m, s in params])\n",
    "\n",
    "training_set = prepare_dataset(NDE, data_samples=params, param_samples=data, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training the posterior\n",
    "NDE.train(\n",
    "    epochs = 50,\n",
    "    dataset = training_set,\n",
    "    pretrain = False,\n",
    "    save = False,\n",
    "    save_history = False,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a mock measurement\n",
    "mock_measurement = np.random.multivariate_normal(np.arange(1, 6)**2, np.diag(np.arange(1, 6)**2), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_gauss(x, mu, sigma):\n",
    "    return -0.5 * np.log(2 * np.pi * sigma) - 0.5 * (x - mu)**2 / sigma**2 \n",
    "\n",
    "def analytic_log_likelihood(d, mu_0, sigma_0):\n",
    "    mu = (np.arange(1, 6)**2).reshape(1, -1) * mu_0.reshape(-1, 1)\n",
    "    cov = (np.arange(1, 6)**2).reshape(1, -1) * sigma_0.reshape(-1, 1)**2\n",
    "    c = -2.5 * np.log(2 * np.pi) - 0.5 * np.log(np.prod(cov, axis = -1))\n",
    "    l = -0.5 * np.sum((d - mu)**2 / cov, axis = -1)\n",
    "    return c + l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One measurement\n",
    "Recover the posteriors for one measurement, `mock_measurement[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ultranest_analytic_posterior(p):\n",
    "    likelihood = analytic_log_likelihood(mock_measurement[0], p[:, 0], p[:, 1])\n",
    "    prior = log_gauss(0.0, p[:, 0], 1.0)\n",
    "    return prior + likelihood\n",
    "\n",
    "def transformation(p):\n",
    "    x = np.zeros(p.shape, dtype = p.dtype)\n",
    "    x[:, 0] = -5 + 10 * p[:, 0]\n",
    "    x[:, 1] = 0.5 + 4.5 * p[:, 1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler_analytic = ultranest.ReactiveNestedSampler(\n",
    "    [\"mu_0\", \"sigma_0\"], \n",
    "    loglike = ultranest_analytic_posterior, \n",
    "    transform = transformation,\n",
    "    vectorized = True,\n",
    "    draw_multiple = True,\n",
    "    ndraw_min = 1000,\n",
    "    ndraw_max = 100000,\n",
    ")\n",
    "result_analytic = sampler_analytic.run(\n",
    "    min_num_live_points = 1000,\n",
    "    min_ess = 1000,\n",
    ")\n",
    "sampler_analytic.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recovering posterior for one mock observation $P(\\mu, \\sigma | d_1)$ is trivial. One would simply call `NDE.conditional_sample`. Let's do that for the first mock measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NDE_sample = NDE.conditional_sample(100000, mock_measurement[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cornerplot(results, fig = None, color = None):\n",
    "    data = np.array(results['weighted_samples']['points'])\n",
    "    weights = np.array(results['weighted_samples']['weights'])\n",
    "    cumsumweights = np.cumsum(weights)\n",
    "\n",
    "    mask = cumsumweights > 1e-4\n",
    "\n",
    "    fig = corner.corner(\n",
    "    data[mask, :],\n",
    "    weights = weights[mask], \n",
    "    fig = fig, \n",
    "    color = color, \n",
    "    truths = [1.0, 1.0], \n",
    "    levels = (0.68, 0.95), \n",
    "    plot_contour=True,\n",
    "    plot_density=False,\n",
    "    plot_datapoints=False,\n",
    "    labels = [\"$\\mu_0$\", \"$\\sigma_0$\"]\n",
    ")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "fig = corner.corner(\n",
    "    NDE_sample.numpy(),\n",
    "    weights = np.ones(100000) / 100000,\n",
    "    truths = [1.0, 1.0], \n",
    "    levels = (0.68, 0.95), \n",
    "    plot_contour=True,\n",
    "    plot_density=False,\n",
    "    plot_datapoints=False,\n",
    "    color = \"blue\",\n",
    "    labels = [\"$\\mu_0$\", \"$\\sigma_0$\"],\n",
    ")\n",
    "fig = cornerplot(result_analytic, fig, \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we have multiple measurements, and we want to recover full posterior $P(\\mu, \\sigma | x_1, x_2, \\ldots, x_{10})$ we can use the following trick.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\mu, \\sigma | x_1, x_2, \\ldots, x_N) &= \\frac{P(x_1, x_2, \\ldots, x_N | \\mu, \\sigma) \\cdot P(\\mu, \\sigma)}{P(x_1, x_2, \\ldots, x_N)} \\\\\n",
    "&= \\frac{1}{P(\\mu, \\sigma)^{N-1}}\\prod_{i=1}^N \\frac{P(x_i | \\mu, \\sigma) \\cdot P(\\mu, \\sigma)}{P(x_i)} \\\\\n",
    "&= P(\\mu, \\sigma)^{1 - N}\\prod_{i=1}^N P(\\mu, \\sigma | x_i)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Use this trick to recover the full posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ultranest_NDE_posterior(p):\n",
    "    N = 10\n",
    "    posterior_sum = np.sum(np.array([NDE.log_prob(p, mock).numpy() for mock in mock_measurement]), axis = 0)\n",
    "    prior = log_gauss(0.0, p[:, 0], 1.0)\n",
    "    return posterior_sum + (1 - N) * prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultranest_analytic_posterior(p):\n",
    "    likelihood = np.sum(np.array([analytic_log_likelihood(mock, p[:, 0], p[:, 1]) for mock in mock_measurement]), axis = 0)\n",
    "    prior = log_gauss(0.0, p[:, 0], 1.0)\n",
    "    return prior + likelihood\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_analytic = ultranest.ReactiveNestedSampler(\n",
    "    [\"mu_0\", \"sigma_0\"], \n",
    "    loglike = ultranest_analytic_posterior, \n",
    "    transform = transformation,\n",
    "    vectorized = True,\n",
    "    draw_multiple = True,\n",
    "    ndraw_min = 1000,\n",
    "    ndraw_max = 100000,\n",
    ")\n",
    "result_analytic = sampler_analytic.run(\n",
    "    min_num_live_points = 1000,\n",
    "    min_ess = 1000,\n",
    ")\n",
    "sampler_analytic.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler_NDE = ultranest.ReactiveNestedSampler(\n",
    "    [\"mu_0\", \"sigma_0\"], \n",
    "    loglike = ultranest_NDE_posterior, \n",
    "    transform = transformation,\n",
    "    vectorized = True,\n",
    "    draw_multiple = True,\n",
    "    ndraw_min = 1000,\n",
    "    ndraw_max = 100000,\n",
    ")\n",
    "result_NDE = sampler_NDE.run(\n",
    "    min_num_live_points = 1000,\n",
    "    min_ess = 1000,\n",
    ")\n",
    "sampler_NDE.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "fig = cornerplot(result_NDE, fig, \"blue\")\n",
    "fig = cornerplot(result_analytic, fig, \"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
